{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"../\")\n",
    "from src.data.smile import SmileData\n",
    "from src.utils import make_binary\n",
    "from src.utils.score import Merger\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import ndarray\n",
    "from typing import Callable\n",
    "from numpy import stack\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data: str = \"../data.nosync/dataset_smile_challenge_unravelled_train_cut10_stadd.npy\"\n",
    "data = SmileData(path_to_data=path_to_data, test=False, debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_configs = dict(\n",
    "    criterion=\"mutual information\",\n",
    "    method=\"percentage\",\n",
    "    method_attribute=51,\n",
    "    joined=False,\n",
    "    deep_features=False,\n",
    ")\n",
    "\n",
    "\n",
    "data.feature_selection(**feature_selection_configs)\n",
    "\n",
    "x = data.get_handcrafted_features()\n",
    "y = data.get_labels()\n",
    "y = make_binary(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070,)\n",
      "(2070,)\n",
      "(2070,)\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "y_1 = randint(low=0, high=2, size=2070)\n",
    "y_2 = randint(low=0, high=2, size=2070)\n",
    "y_3 = randint(low=0, high=2, size=2070)\n",
    "print(y_1.shape)\n",
    "print(y_2.shape)\n",
    "print(y_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6210 into shape (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/leonardoalchieri/Desktop/GIT/StressChallange/notebooks/pipeline-testing.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/StressChallange/notebooks/pipeline-testing.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m stack\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/StressChallange/notebooks/pipeline-testing.ipynb#ch0000004?line=2'>3</a>\u001b[0m merger \u001b[39m=\u001b[39m Merger\u001b[39m.\u001b[39m_get_merge_strategy(\u001b[39m'\u001b[39m\u001b[39mmajority_voting\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/StressChallange/notebooks/pipeline-testing.ipynb#ch0000004?line=4'>5</a>\u001b[0m merger(stack([y_1, y_2, y_3], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m20\u001b[39;49m))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6210 into shape (20)"
     ]
    }
   ],
   "source": [
    "from numpy import stack\n",
    "\n",
    "merger = Merger._get_merge_strategy('majority_voting')\n",
    "\n",
    "merger(stack([y_1, y_2, y_3], axis=1).reshape(-1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "y = array(y).reshape(-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalClassifier(ClassifierMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        models: dict[str, ClassifierMixin],\n",
    "        fusion_method: Callable | ClassifierMixin | str,\n",
    "        time_length: int,\n",
    "        probability: bool = False,\n",
    "    ):\n",
    "        \"\"\"Classifier to train a multi-modal approach. The classifier will train\n",
    "        a model (at minute-level) for\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : dict[str, ClassifierMixin]\n",
    "            _description_\n",
    "        fusion_method : Callable | ClassifierMixin | str\n",
    "            _description_\n",
    "        time_length : int\n",
    "            _description_\n",
    "        probability : bool, optional\n",
    "            _description_, by default False\n",
    "        \"\"\"\n",
    "        self.time_length = time_length\n",
    "        self.data_names: list[str] = list(models.keys())\n",
    "        self.models = models\n",
    "        self.probability = probability\n",
    "        if isinstance(fusion_method, str):\n",
    "            self.fusion_method = Merger._get_merge_strategy(fusion_method)\n",
    "        else:\n",
    "            self.fusion_method = fusion_method\n",
    "\n",
    "    def fit(self, x: dict[str, ndarray], y: ndarray):\n",
    "        if not isinstance(x, dict):\n",
    "            raise TypeError(f\"x must be a dict. Got {type(x)} instead\")\n",
    "\n",
    "        y_preds: dict[str, ndarray] = {}\n",
    "        for data_name, model in self.models.items():\n",
    "            model.fit(x[data_name], y)\n",
    "            y_preds[data_name] = (\n",
    "                model.predict(x[data_name])\n",
    "                if not self.probability\n",
    "                else model.predict_proba(x[data_name])[:, 1]\n",
    "            )\n",
    "            self.models[data_name] = model\n",
    "\n",
    "        if not isinstance(self.fusion_method, str) and not callable(self.fusion_method):\n",
    "            warn(f\"Assuming fusion method to be ML based.\")\n",
    "            # logger.warning('Assuming fusion method to be ML based')\n",
    "            y_pred = self._ravel_back_results(y_preds=y_preds)\n",
    "\n",
    "            y = Merger.check_truth(Merger.ravel_back(y=y, time_length=self.time_length))\n",
    "            self.fusion_method.fit(y_pred, y)\n",
    "\n",
    "    def _ravel_back_results(self, y_preds: ndarray) -> ndarray:\n",
    "        y_pred: ndarray = stack(list(y_preds.values()), axis=1)\n",
    "        y_pred: ndarray = y_pred.reshape(-1, self.time_length * y_pred.shape[-1])\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, x: dict[str, ndarray]) -> ndarray:\n",
    "        y_preds: dict[str, ndarray] = {}\n",
    "        for data_name, model in self.models.items():\n",
    "            y_preds[data_name] = (\n",
    "                model.predict(x[data_name])\n",
    "                if not self.probability\n",
    "                else model.predict_proba(x[data_name])[:, 1]\n",
    "            )\n",
    "\n",
    "        y_pred = self._ravel_back_results(y_preds=y_preds)\n",
    "        if not isinstance(self.fusion_method, str) and not callable(self.fusion_method):\n",
    "            return self.fusion_method.predict(y_pred)\n",
    "        else:\n",
    "            return self.fusion_method(y_pred)\n",
    "\n",
    "    def score(self, x: dict[str, ndarray], y: ndarray) -> float:\n",
    "        y_pred = self.predict(x)\n",
    "        y = Merger.check_truth(Merger.ravel_back(y=y, time_length=self.time_length))\n",
    "        return accuracy_score(y_pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, logger, delayed\n",
    "from src.utils.cv import make_unravelled_folds\n",
    "from copy import deepcopy\n",
    "\n",
    "n_jobs: int = -1\n",
    "verbose: int = 1\n",
    "pre_dispatch: str = \"all\"\n",
    "\n",
    "\n",
    "def fit_and_score(\n",
    "    estimator: ClassifierMixin,\n",
    "    x: dict[str, ndarray] | ndarray,\n",
    "    y: ndarray,\n",
    "    train_idx: ndarray,\n",
    "    test_idx: ndarray,\n",
    ") -> float:\n",
    "    if isinstance(x, dict):\n",
    "        x_train: dict[str, ndarray] = {\n",
    "            data_name: x[data_name][train_idx] for data_name in x.keys()\n",
    "        }\n",
    "        x_test: dict[str, ndarray] = {\n",
    "            data_name: x[data_name][test_idx] for data_name in x.keys()\n",
    "        }\n",
    "    else:\n",
    "        x_train = x[train_idx]\n",
    "        x_test = x[test_idx]\n",
    "    y_train: ndarray = y[train_idx]\n",
    "\n",
    "    y_test: ndarray = y[test_idx]\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    return estimator.score(x_test, y_test)\n",
    "\n",
    "\n",
    "def cross_validation(\n",
    "    x: dict[str, ndarray] | ndarray,\n",
    "    y: ndarray,\n",
    "    estimator: ClassifierMixin,\n",
    "    cv,\n",
    "    n_jobs: int | None = None,\n",
    ") -> list[float]:\n",
    "    parallel = Parallel(\n",
    "        n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch, backend=\"loky\"\n",
    "    )\n",
    "    results = parallel(\n",
    "        delayed(fit_and_score)(\n",
    "            deepcopy(estimator),\n",
    "            x,\n",
    "            y,\n",
    "            train_idx,\n",
    "            test_idx,\n",
    "        )\n",
    "        for train_idx, test_idx in cv\n",
    "    )\n",
    "    return list(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "/var/folders/rc/t3h_b88s3vbg5dcd4pnlgskr0000gp/T/ipykernel_52103/984517011.py:47: UserWarning: Assuming fusion method to be ML based.\n",
      "  warn(f\"Assuming fusion method to be ML based.\")\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.3s finished\n"
     ]
    }
   ],
   "source": [
    "cv: list[tuple[ndarray, ndarray]] = make_unravelled_folds(t=10, n_folds=10, n_data=2070)\n",
    "\n",
    "models = {\n",
    "    \"ECG_features\": AdaBoostClassifier(),\n",
    "    \"ST_features\": AdaBoostClassifier(),\n",
    "    \"GSR_features\": AdaBoostClassifier(),\n",
    "}\n",
    "fusion_method = \"majority_voting\"\n",
    "\n",
    "multimodal_classifier = MultiModalClassifier(\n",
    "    models=models, fusion_method=SVC(kernel=\"rbf\"), time_length=10, probability=True\n",
    ")\n",
    "\n",
    "res = cross_validation(x=x, y=y, estimator=multimodal_classifier, cv=cv, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal: 57.874396135265705 +- 2.9498062583034823\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean, std, sqrt\n",
    "print(f\"Multimodal: {mean(res)*100} +- {std(res)*100/sqrt(9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.8s finished\n"
     ]
    }
   ],
   "source": [
    "# unimodal\n",
    "res = dict()\n",
    "for data_name, data in x.items():\n",
    "    res[data_name] = cross_validation(x=data, y=y, estimator=SVC(), cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG_features: 58.971014492753625 +- 2.943135807567352\n",
      "GSR_features: 47.34299516908212 +- 3.106388296395339\n",
      "ST_features: 58.60386473429953 +- 3.781226418052658\n"
     ]
    }
   ],
   "source": [
    "for data_name, result in res.items():\n",
    "    print(f\"{data_name}: {mean(result)*100} +- {std(result)*100/sqrt(9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stuff: list[tuple[str, str]] = [\n",
    "    (\"hand_crafted_features\", \"ECG_features\"),\n",
    "    (\"hand_crafted_features\", \"GSR_features\"),\n",
    "]\n",
    "res = [subset for subset in all_subsets(stuff) if len(subset) != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hand_crafted_features', 'ECG_features')\n",
      "('hand_crafted_features', 'GSR_features')\n",
      "('hand_crafted_features', 'ECG_features')\n",
      "('hand_crafted_features', 'GSR_features')\n"
     ]
    }
   ],
   "source": [
    "for couple in res:\n",
    "    print(lust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086956521739131"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "mean([0.40096618357487923,\n",
    "0.3140096618357488,\n",
    "0.5024154589371981,\n",
    "0.5362318840579711,\n",
    "0.5942028985507246,\n",
    "0.642512077294686,\n",
    "0.4927536231884058,\n",
    "0.5217391304347826,\n",
    "0.5797101449275363,\n",
    "0.5024154589371981])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('stress')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643980dca58626c9db13de6fa762274e0ff1919d6fc081f47feb3d972ff3a549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
